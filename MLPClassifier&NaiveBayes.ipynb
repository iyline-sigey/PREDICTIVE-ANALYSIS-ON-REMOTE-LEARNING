{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPClassifier&NaiveBayes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMD5ckeTLdIIUAZ+mju/ioL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyline-sigey/PREDICTIVE-ANALYSIS-ON-REMOTE-LEARNING/blob/Modelling/MLPClassifier%26NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py5OXkOi10RS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#for metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VInc5rW8vnRx"
      },
      "source": [
        "df_clean = pd.read_csv('/content/modeling_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL0m1TXAYHa_"
      },
      "source": [
        "### Neural Networks MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TTWmHtEg83B"
      },
      "source": [
        "#Declaring our X and Y variables\n",
        "X = df_clean.clean_tweet.values\n",
        "y = df_clean['class'].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1C6kYl8hKN0"
      },
      "source": [
        "# Train Test Split \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FF2Opdoslp5"
      },
      "source": [
        "# set a vocabulary size. This is the maximum number of words that can be used.\n",
        "vocabulary_size = 10000\n",
        "\n",
        "# create the tokenizer that comes with Keras.\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# convert the texts to sequences.\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYzwZV8luZqs"
      },
      "source": [
        "max_words = 5000\n",
        "max_len = 5000\n",
        "\n",
        "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=200)\n",
        "X_val_seq_padded  = pad_sequences(X_val_seq, maxlen=200)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1oTykc4hYZC",
        "outputId": "2e99734a-27d8-45bc-9994-66eb2fa2eb09"
      },
      "source": [
        "#creating an instamce ofthe model\n",
        "mlp = MLPClassifier(hidden_layer_sizes = (13, 13,13), max_iter = 500)\n",
        "\n",
        "# fitting the data\n",
        "mlp.fit(X_train_seq_padded,y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxf48AA4hpbJ",
        "outputId": "2c3b87bc-6eb9-4e14-86df-f936ec526d16"
      },
      "source": [
        "# Now that we have our model in place, let's do the prediction\n",
        "from sklearn import metrics\n",
        "pred = mlp.predict(X_val_seq_padded)\n",
        "\n",
        "mlp_nn = metrics.accuracy_score(pred,y_test)*100\n",
        "\n",
        "# Evaluating the performance of ur model\n",
        "\n",
        "print('The accuracy of the model is ',metrics.accuracy_score(y_test, pred))\n",
        "\n",
        "print (confusion_matrix(y_test,pred))\n",
        "\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model is  0.6290322580645161\n",
            "[[11 11]\n",
            " [12 28]]\n",
            "-----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.50      0.49        22\n",
            "           1       0.72      0.70      0.71        40\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.60      0.60      0.60        62\n",
            "weighted avg       0.63      0.63      0.63        62\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKVcYAlEh29c",
        "outputId": "0910085c-43e8-4bd7-9627-f9c0cb8e17fd"
      },
      "source": [
        "# Extracting the weights and bias vectors\n",
        "\n",
        "# Checking the number of weights \n",
        "len(mlp.coefs_) \n",
        "\n",
        "# Checking the number of biases \n",
        "len(mlp.intercepts_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWXYXe5gWJkx"
      },
      "source": [
        "Naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ik2_TQKfwNe"
      },
      "source": [
        "#Declaring our X and Y variables\n",
        "X = df_clean.clean_tweet.values\n",
        "y = df_clean['class'].values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0kODYVufwNf"
      },
      "source": [
        "# Train Test Split \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oef3wJ6lfwNf"
      },
      "source": [
        "# set a vocabulary size. This is the maximum number of words that can be used.\n",
        "vocabulary_size = 10000\n",
        "\n",
        "# create the tokenizer that comes with Keras.\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# convert the texts to sequences.\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71SOMJX4fwNg"
      },
      "source": [
        "max_words = 5000\n",
        "max_len = 5000\n",
        "\n",
        "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=200)\n",
        "X_val_seq_padded  = pad_sequences(X_val_seq, maxlen=200)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D3oU5qEWNng",
        "outputId": "7af19630-40b3-4893-8cf4-e3fb9a4e9722"
      },
      "source": [
        "# Training the Model\n",
        "# We will start by splitting our data into training and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Fitting our model \n",
        "# Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \n",
        "# For text classification problems, the Multinomial Naive Bayes Classifier is well-suited\n",
        "# \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train_seq_padded, y_train)\n",
        "\n",
        "# Evaluating the Model\n",
        "# Once we have put together our classifier, we can evaluate its performance in the testing set\n",
        "# \n",
        "predicted = model.predict(X_val_seq_padded)\n",
        "print(np.mean(predicted == y_test))\n",
        "print(confusion_matrix(y_test, predicted))\n",
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.532258064516129\n",
            "[[14  9]\n",
            " [20 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.61      0.49        23\n",
            "           1       0.68      0.49      0.57        39\n",
            "\n",
            "    accuracy                           0.53        62\n",
            "   macro avg       0.55      0.55      0.53        62\n",
            "weighted avg       0.58      0.53      0.54        62\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ESl6pWtXHhV",
        "outputId": "84221737-6857-4d7b-a941-62e4da74d838"
      },
      "source": [
        "# Training our model and printing out metrics\n",
        "# \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(X_train_seq_padded, y_train) \n",
        "predicted = model.predict(X_val_seq_padded)\n",
        "print(np.mean(predicted == y_test))\n",
        "print(confusion_matrix(y_test, predicted))\n",
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3548387096774194\n",
            "[[21  2]\n",
            " [38  1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.91      0.51        23\n",
            "           1       0.33      0.03      0.05        39\n",
            "\n",
            "    accuracy                           0.35        62\n",
            "   macro avg       0.34      0.47      0.28        62\n",
            "weighted avg       0.34      0.35      0.22        62\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}